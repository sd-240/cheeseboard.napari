{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discovering files...\n",
      "Initial file count: 8\n",
      "['Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R4567_task_day06-07282025120514-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R4567_task_day07-07292025162301-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R_task_day07-07282025162805-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\L4441_hab_day01-08052025115729-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\L4446_hab_day03-08072025102037-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4447_hab_day02-08062025103921-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4489_hab_day03-08072025104730-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4509_task_day07-07282025154250-0000.avi']\n",
      "filter to just probe sessions to start\n",
      "['Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R4567_task_day06-07282025120514-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R4567_task_day07-07292025162301-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\2L1R_task_day07-07282025162805-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\L4441_hab_day01-08052025115729-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\L4446_hab_day03-08072025102037-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4447_hab_day02-08062025103921-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4489_hab_day03-08072025104730-0000.avi', 'Y:\\\\laura_berkowitz\\\\behavior_validation\\\\appps1_cheeseboard\\\\dlc_videos\\\\R4509_task_day07-07282025154250-0000.avi']\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R4567_task_day06-07282025120514-0000.avi --- 0 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R4567_task_day06-07282025120514-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R4567_task_day07-07292025162301-0000.avi --- 1 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R4567_task_day07-07292025162301-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R_task_day07-07282025162805-0000.avi --- 2 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R_task_day07-07282025162805-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\L4441_hab_day01-08052025115729-0000.avi --- 3 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\L4441_hab_day01-08052025115729-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\L4446_hab_day03-08072025102037-0000.avi --- 4 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\L4446_hab_day03-08072025102037-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4447_hab_day02-08062025103921-0000.avi --- 5 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4447_hab_day02-08062025103921-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4489_hab_day03-08072025104730-0000.avi --- 6 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4489_hab_day03-08072025104730-0000.avi --- not annotated\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4509_task_day07-07282025154250-0000.avi --- 7 of 8 files\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "hey\n",
      "suckjerja;ldkjf;alskjdfa;lsdkjf\n",
      "Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\R4509_task_day07-07282025154250-0000.avi --- not annotated\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from itertools import compress\n",
    "from pathlib import Path\n",
    "\n",
    "import napari\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "\n",
    "# Goes through all the layers of the video, extracting the coordinates,\n",
    "# frames, and the visible data and creates a DataFrame with the according\n",
    "# coordinates for each frame.\n",
    "#\n",
    "def save_layers_to_video_directory(viewer, video_path, point_layers):\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    #A layer is a level at which an aspect of the video can be manipulated (i.e.,\n",
    "    #can contain videos, audio, images, text, or effects). Layers are used to\n",
    "    #superimpose on video clip over another or to add special efects.\n",
    "    for layer in point_layers:\n",
    "        # Extract point coordinates (N, 2)\n",
    "        points = layer.data\n",
    "        # Loads the frame data and, if not found, replaces with 0s\n",
    "        frames = layer.metadata.get(\"frames\", np.zeros(len(points), dtype=int))\n",
    "        # Loads the visible data and, if not found, replaces with 1s (always True)\n",
    "        visible = layer.metadata.get(\"visible\", np.ones(len(points), dtype=bool))\n",
    "\n",
    "        if len(points) == 0:\n",
    "            print(f\"No data to save for layer '{layer.name}'.\")\n",
    "            continue  # Skip empty layers\n",
    "\n",
    "        # Create DataFrame with required columns\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"index\": np.arange(len(points)),  # Index of each point\n",
    "                \"axis-0\": frames,  # Frame number\n",
    "                \"axis-1\": points[:, 0],  # X-coordinates -> first column of array\n",
    "                \"axis-2\": points[:, 1],  # Y-coordinates -> second column of array\n",
    "            }\n",
    "        )\n",
    "\n",
    "        save_path = video_dir / f\"{layer.name}.csv\"\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Saved {layer.name} points to {save_path}\")\n",
    "\n",
    "#\n",
    "def update_point_visibility(layer, viewer):\n",
    "    if \"frames\" not in layer.metadata:\n",
    "        return\n",
    "\n",
    "    # Gets the current frame from the video, starting from where the viewer is\n",
    "    current_frame = viewer.dims.current_step[0]\n",
    "    # Gets the metadata associated with frames\n",
    "    frames = layer.metadata[\"frames\"]\n",
    "\n",
    "    # Update visibility based on current -> so visibility is true for the frames\n",
    "    # before and at the frame the viewer is on\n",
    "    visible = frames <= current_frame\n",
    "    layer.metadata[\"visible\"] = visible\n",
    "\n",
    "    # Update the displayed points -> points that are displayed are the ones\n",
    "    # that are listed as visible\n",
    "    if len(layer.data) > 0:\n",
    "        layer.shown = visible\n",
    "\n",
    "\n",
    "def store_frame_metadata(layer, viewer):\n",
    "    current_frame = viewer.dims.current_step[0]  # Get current frame number\n",
    "    num_points = len(layer.data)  # Total points in the layer\n",
    "\n",
    "    if \"frames\" not in layer.metadata:\n",
    "        layer.metadata[\"frames\"] = np.zeros(num_points, dtype=int)  # Initialize\n",
    "        layer.metadata[\"visible\"] = np.ones(\n",
    "            num_points, dtype=bool\n",
    "        )  # Initialize visibility\n",
    "\n",
    "    existing_frames = layer.metadata[\"frames\"]  # Get stored frame numbers\n",
    "\n",
    "    # If new points were added, store their frame numbers\n",
    "    if num_points > len(existing_frames):\n",
    "        new_frames = np.full(\n",
    "            num_points - len(existing_frames), current_frame\n",
    "        )  # Assign current frame to new points\n",
    "        layer.metadata[\"frames\"] = np.concatenate(\n",
    "            [existing_frames, new_frames]\n",
    "        )  # Update frames\n",
    "        # New points should be visible if current frame >= their frame\n",
    "        new_visible = np.ones(num_points - len(existing_frames), dtype=bool)\n",
    "        layer.metadata[\"visible\"] = np.concatenate(\n",
    "            [layer.metadata[\"visible\"], new_visible]\n",
    "        )\n",
    "\n",
    "    # Update visibility for all points\n",
    "    update_point_visibility(layer, viewer)\n",
    "\n",
    "\n",
    "# Goes through each layer and modifies data based on certain events, saving the\n",
    "# data to the layer when press 'S' key\n",
    "def annotate_video(video_path):\n",
    "    vr = VideoReaderNP(video_path)\n",
    "    viewer = napari.view_image(vr, name=video_path)\n",
    "\n",
    "    # Add point layers\n",
    "    rewards_layer = viewer.add_points(name=\"rewards\", face_color=\"red\", size=10)\n",
    "    start_layer = viewer.add_points(name=\"start\", face_color=\"green\", size=10)\n",
    "    trials_layer = viewer.add_points(name=\"trials\", face_color=\"blue\", size=10)\n",
    "\n",
    "    point_layers = [rewards_layer, start_layer, trials_layer]\n",
    "\n",
    "    # Attach event listeners -> so whenever the data changes (i.e., points\n",
    "    # are removed, added, or modified) or the viewer changes a frame,\n",
    "    # updates metadata and changes visuals (i.e., visible points), respectively\n",
    "    for layer in point_layers:\n",
    "        # Update frame metadata when points are added\n",
    "        layer.events.data.connect(\n",
    "            lambda event, l=layer: store_frame_metadata(l, viewer)\n",
    "        )\n",
    "\n",
    "        # Update visibility when frame changes\n",
    "        viewer.dims.events.current_step.connect(\n",
    "            lambda event: update_point_visibility(layer, viewer)\n",
    "        )\n",
    "\n",
    "    # Bind save function to 'S' key\n",
    "    @viewer.bind_key(\"Shift-S\")\n",
    "    def save_on_keypress(viewer):\n",
    "        save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "\n",
    "    napari.run()\n",
    "\n",
    "# Checks trial durations, number of trials, number of rewards, and each trial\n",
    "# has only 1 start time\n",
    "def verify_manual_annotation(video_path, fs=40, trial_wiggle_room=10):\n",
    "    if not is_annotated(video_path):\n",
    "        print(f\"{video_path} --- not annotated\")\n",
    "        return\n",
    "\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    trials = pd.read_csv(os.path.join(video_dir, \"trials.csv\"))\n",
    "    rewards = pd.read_csv(os.path.join(video_dir, \"rewards.csv\"))\n",
    "    start = pd.read_csv(os.path.join(video_dir, \"start.csv\"))\n",
    "\n",
    "    # check if any trial durations\n",
    "    trials = trials.sort_values(\"axis-0\").reset_index(drop=True)\n",
    "    # fills the even indexes of trials with start times\n",
    "    start_ind = trials[trials.index % 2 == 0][\"axis-0\"]\n",
    "    # fills the odd indexes of trials with end times\n",
    "    stop_ind = trials[trials.index % 2 == 1][\"axis-0\"]\n",
    "    # converts the indices into seconds by dividing by sampling frequency\n",
    "    starts = start_ind / fs\n",
    "    stops = stop_ind / fs\n",
    "    # check if same number of starts and stops -> sanity check ig?\n",
    "    assert len(starts) == len(stops), (\n",
    "        f\"Found {len(starts)} starts and {len(stops)} stops\"\n",
    "    )\n",
    "    # get durations per trial\n",
    "    durations = stops.values - starts.values\n",
    "\n",
    "    # check if any trial is longer than 360 seconds\n",
    "    assert durations.max() < 60 * 6, f\"Found {durations.max()} seconds\"\n",
    "    if durations.max() > 90:\n",
    "        print(f\"{video_path} --- Found {durations.max()} seconds\")\n",
    "\n",
    "    # check if any trial is shorter than 90 seconds\n",
    "    if durations.min() < 90:\n",
    "        test = 1\n",
    "    assert durations.min() > 5, f\"Found {durations.min()} seconds\"\n",
    "\n",
    "    # check if more than 25 trials\n",
    "    assert durations.shape[0] <= 30, f\"Found {durations.shape[0]} trials\"\n",
    "\n",
    "    # check if at least 2 rewards\n",
    "    assert rewards.shape[0] >= 2, f\"Found {rewards.shape[0]} rewards\"\n",
    "\n",
    "    # check if 1 start\n",
    "    assert start.shape[0] == 1, f\"Found {start.shape[0]} start points\"\n",
    "\n",
    "    print(f\"{video_path} --- verified\")\n",
    "\n",
    "\n",
    "def is_annotated(video_path):\n",
    "    video_dir = Path(video_path).parent\n",
    "    print(\"hey\")\n",
    "    if os.path.exists(os.path.join(video_dir, \"rewards.csv\")) & os.path.exists(os.path.join(video_dir, \"start.csv\")) & os.path.exists(os.path.join(video_dir, \"trials.csv\")):\n",
    "        print(\"treldkjf\")\n",
    "    else:\n",
    "        print(\"suckjerja;ldkjf;alskjdfa;lsdkjf\")\n",
    "    return (\n",
    "        os.path.exists(os.path.join(video_dir, \"rewards.csv\"))\n",
    "        & os.path.exists(os.path.join(video_dir, \"start.csv\"))\n",
    "        & os.path.exists(os.path.join(video_dir, \"trials.csv\"))\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"discovering files...\")\n",
    "\n",
    "    # files = glob.glob(r\"U:\\data\\hpc_ctx_project\\**\\*.avi\", recursive=True)\n",
    "\n",
    "    # files_series = pd.Series(files)\n",
    "    # idx = (\n",
    "    #     files_series.str.contains(\"cheeseboard|cheesboard|open_field|acquisition|probe\")\n",
    "    #     & ~files_series.str.contains(\"backup\")\n",
    "    #     & ~files_series.str.contains(\"test\")\n",
    "    # )\n",
    "\n",
    "    # files = list(compress(files, idx))\n",
    "    # basepaths = pd.read_csv(\"Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\sample_data.csv\").basepath.unique()\n",
    "\n",
    "    # files = []\n",
    "\n",
    "    # for folder in basepaths:\n",
    "    #     print('hei')\n",
    "    #     files.extend(glob.glob(os.path.join(folder, \"**\", \"*.avi\"), recursive=True))\n",
    "\n",
    "    files = glob.glob(r'Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\*.avi')\n",
    "\n",
    "    print(f\"Initial file count: {len(files)}\")\n",
    "    print(files)\n",
    "\n",
    "    print(\"filter to just probe sessions to start\")\n",
    "    files_series = pd.Series(files)\n",
    "    idx = ~files_series.str.contains(\"backup\") & ~files_series.str.contains(\"test\")\n",
    "    files = list(compress(files, idx))\n",
    "    print(files)\n",
    "    for video_path_i, video_path in enumerate(files):\n",
    "        print(f\"{video_path} --- {video_path_i} of {len(files)} files\")\n",
    "\n",
    "        video_dir = Path(video_path).parent\n",
    "\n",
    "        if is_annotated(video_path):\n",
    "            verify_manual_annotation(video_path)\n",
    "            continue\n",
    "\n",
    "        annotate_video(video_path)\n",
    "        verify_manual_annotation(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(r'Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\*.avi')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a new napari viewer\n",
    "# viewer = napari.Viewer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "path=r\"Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R_task_day07-07282025162805-0000.avi\"\n",
    "vr = VideoReaderNP(path)\n",
    "# with napari.gui_qt():\n",
    "viewer = napari.view_image(vr, name=path)\n",
    "# Define initial points for each layer (you can modify these as needed)\n",
    "rewards_points = np.array([])  # Example points for rewards\n",
    "start_points = np.array([])    # Example points for start\n",
    "trials_points = np.array([])  # Example points for trials\n",
    "\n",
    "# Add point layers to the viewer\n",
    "rewards_layer = viewer.add_points(rewards_points, name='rewards', face_color='red', size=10, properties={'frame':[]})\n",
    "start_layer = viewer.add_points(start_points, name='start', face_color='green', size=10, properties={'frame':[]})\n",
    "trials_layer = viewer.add_points(trials_points, name='trials', face_color='blue', size=10, properties={'frame':[]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def save_layers_to_video_directory(viewer, video_path, point_layers):\n",
    "    video_dir = Path(video_path).parent\n",
    "    # current_frame = viewer.dims.current_step[0]\n",
    "    for layer in point_layers:\n",
    "        save_path = video_dir / f\"{layer.name}_test.csv\"\n",
    "        layer.save(save_path)\n",
    "        print(f\"Saved {layer.name} points to {save_path}\")\n",
    "\n",
    "\n",
    "# Function to add frame number when a point is added\n",
    "def add_frame_to_point(layer, event):\n",
    "    current_frame = viewer.dims.current_step[0]  # Get the current frame number\n",
    "    if \"frame\" not in layer.properties:\n",
    "        layer.properties[\"frame\"] = np.array([])\n",
    "    layer.properties[\"frame\"] = np.append(layer.properties[\"frame\"], current_frame)\n",
    "    \n",
    "# Path to your video file\n",
    "# video_path = \"path/to/your/video.mp4\"\n",
    "video_path=r\"Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R_task_day07-07282025162805-0000.avi\"\n",
    "\n",
    "vr = VideoReaderNP(video_path)\n",
    "# with napari.gui_qt():\n",
    "viewer = napari.view_image(vr, name=video_path)\n",
    "\n",
    "# Add initial point layers (optional)\n",
    "rewards_layer = viewer.add_points(name='rewards', face_color='red', size=10)\n",
    "start_layer = viewer.add_points(name='start', face_color='green', size=10)\n",
    "trials_layer = viewer.add_points(name='trials', face_color='blue', size=10)\n",
    "\n",
    "point_layers = [rewards_layer,start_layer,trials_layer]\n",
    "\n",
    "# Connect the save function to the viewer's close event\n",
    "@viewer.bind_key('S')  # Bind to a keypress (e.g., 'S' for save)\n",
    "def save_on_keypress(viewer):\n",
    "    save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "\n",
    "# Run the napari GUI\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from napari_video.napari_video import VideoReaderNP\n",
    "\n",
    "def save_layers_to_video_directory(viewer, video_path, point_layers):\n",
    "    video_dir = Path(video_path).parent\n",
    "\n",
    "    for layer in point_layers:\n",
    "        points = layer.data  # Extract point coordinates (N, 2)\n",
    "        frames = layer.properties.get(\"frame\", np.array([]))  # Extract stored frame indices\n",
    "        \n",
    "        if len(points) == 0 or len(frames) == 0:\n",
    "            print(f\"No data to save for layer '{layer.name}'.\")\n",
    "            continue  # Skip empty layers\n",
    "        \n",
    "        # Ensure correct shape\n",
    "        frames = np.asarray(frames).reshape(-1, 1)  # Ensure frames are a column\n",
    "        points = np.asarray(points)  # Ensure points are NumPy array\n",
    "\n",
    "        # Combine index, frame, x, y into a DataFrame\n",
    "        df = pd.DataFrame(\n",
    "            np.column_stack([np.arange(len(points)), frames, points]),\n",
    "            columns=[\"index\", \"axis-0\", \"axis-1\", \"axis-2\"]\n",
    "        )\n",
    "\n",
    "        save_path = video_dir / f\"{layer.name}_annotations.csv\"\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Saved {layer.name} points to {save_path}\")\n",
    "\n",
    "# Function to add frame number when a point is added\n",
    "def add_frame_to_point(layer, event, viewer):\n",
    "    current_frame = viewer.dims.current_step[0]  # Get current frame number\n",
    "\n",
    "    if \"frame\" not in layer.properties:\n",
    "        layer.properties[\"frame\"] = np.array([])  # Initialize frame property\n",
    "\n",
    "    layer.properties[\"frame\"] = np.append(layer.properties[\"frame\"], current_frame)\n",
    "\n",
    "# Path to your video file\n",
    "video_path = r\"Y:\\laura_berkowitz\\behavior_validation\\appps1_cheeseboard\\dlc_videos\\2L1R_task_day07-07282025162805-0000.avi\"\n",
    "\n",
    "vr = VideoReaderNP(video_path)\n",
    "viewer = napari.view_image(vr, name=video_path)\n",
    "\n",
    "# Add point layers for annotations\n",
    "rewards_layer = viewer.add_points(name='rewards', face_color='red', size=10)\n",
    "start_layer = viewer.add_points(name='start', face_color='green', size=10)\n",
    "trials_layer = viewer.add_points(name='trials', face_color='blue', size=10)\n",
    "\n",
    "point_layers = [rewards_layer, start_layer, trials_layer]\n",
    "\n",
    "# Attach event listener to each layer using partial to avoid lambda issues\n",
    "for layer in point_layers:\n",
    "    layer.events.data.connect(partial(add_frame_to_point, layer, viewer=viewer))\n",
    "\n",
    "# Bind save function to 'S' key\n",
    "@viewer.bind_key('S')\n",
    "def save_on_keypress(viewer):\n",
    "    save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "\n",
    "@viewer.events.closed.connect\n",
    "def save_on_close(event):\n",
    "    save_layers_to_video_directory(viewer, video_path, point_layers)\n",
    "    print(\"Auto-saved on viewer close\")\n",
    "\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
